{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from logistic import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_raw=pd.read_csv('./ex4x.dat',header=None,sep=r'\\s+')\n",
    "labels_raw=pd.read_csv('./ex4y.dat',header=None,sep=r'\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2),(80, 1)\n"
     ]
    }
   ],
   "source": [
    "features=np.column_stack((features_raw[0].values.tolist(),features_raw[1].values.tolist()))\n",
    "labels=np.array(labels_raw[0].values.tolist()).reshape(-1,1)\n",
    "print('{},{}'.format(features.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K倍交叉验证数据切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_split(data,k,test_data_index):\n",
    "    data_copy=np.array(data)\n",
    "    splited_datas=np.array_split(data_copy,k)\n",
    "    test_data=splited_datas[test_data_index]\n",
    "    train_data=[]\n",
    "    for i in range(k):\n",
    "        if i==test_data_index:\n",
    "            continue\n",
    "        train_data.extend(splited_datas[i])\n",
    "    \n",
    "    train_data=np.array(train_data).reshape(-1,data.shape[1])\n",
    "    return test_data,train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机梯度下降的逻辑回归进行5倍交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_history=[]\n",
    "k=5\n",
    "max_epoch=5000\n",
    "lr=0.1\n",
    "batch=8\n",
    "for index in range(k):\n",
    "    features_test_data,features_train_data=K_fold_split(features,k,index)\n",
    "    labels_test_data,labels_train_data=K_fold_split(labels,k,index)\n",
    "    lgr=LogisticRegression(features_train_data,labels_train_data)\n",
    "    lgr.train(max_epoch,lr,batch)\n",
    "    acc=lgr.compute_accuracy(features_test_data,labels_test_data)\n",
    "    \n",
    "    accuracy_history.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Logistic Regression------------------\n",
      "index:0  accuracy:1.0\n",
      "index:1  accuracy:0.5625\n",
      "index:2  accuracy:0.9375\n",
      "index:3  accuracy:0.6875\n",
      "index:4  accuracy:0.625\n",
      "--------------average--------------\n",
      "average accuracy:0.7625\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Logistic Regression------------------\")\n",
    "for index,acc in enumerate(accuracy_history):\n",
    "    print(\"index:{}  accuracy:{}\".format(index,acc))\n",
    "\n",
    "print(\"--------------average--------------\")\n",
    "print(\"average accuracy:{}\".format(np.mean(accuracy_history)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ann(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, activator):\n",
    "        super(Ann, self).__init__()\n",
    "        self.input_layer = tf.keras.layers.Dense(hidden_size, input_shape=(input_size,))\n",
    "        self.hidden_layer = tf.keras.layers.Dense(output_size)\n",
    "        self.activator = activator\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.activator(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = tf.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:Ann, max_epoch, lr, features_train_data, labels_train_data):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    losses = []\n",
    "    loss_fn=tf.nn.sigmoid_cross_entropy_with_logits\n",
    "    for epoch in range(max_epoch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = model(features_train_data)\n",
    "            loss = loss_fn(labels=labels_train_data, logits=output)\n",
    "            losses.append(loss.numpy())\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    res = np.array(data.T)\n",
    "    means = np.mean(res, axis=1)\n",
    "    stds = np.std(res, axis=1)\n",
    "    for i in range(res.shape[0]):\n",
    "        res[i] = (res[i] - means[i]) / stds[i]\n",
    "    res = res.T\n",
    "    return res, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test_data(test_data,means,stds):\n",
    "    res=np.array(test_data.T)\n",
    "    \n",
    "    for i in range(res.shape[0]):\n",
    "        res[i]=(res[i]-means[i])/stds[i]\n",
    "    \n",
    "    res=res.T\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data,threshold=0.5):\n",
    "    res=np.array(data)\n",
    "    for i in range(res.shape[0]):\n",
    "        if res[i][0]>=threshold:\n",
    "            res[i][0]=1\n",
    "        else:\n",
    "            res[i][0]=0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction,labels_test_data):\n",
    "    equal_count=0\n",
    "    total=prediction.shape[0]\n",
    "    for i in range(prediction.shape[0]):\n",
    "        if prediction[i][0]==labels_test_data[i][0]:\n",
    "            equal_count+=1\n",
    "    return equal_count/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=2\n",
    "input_size=2\n",
    "output_size=1\n",
    "max_epoch=5000\n",
    "accuracy_history=[]\n",
    "k=5\n",
    "lr=0.1\n",
    "for index in range(k):\n",
    "    # 数据处理阶段\n",
    "    features_test_data,features_train_data=K_fold_split(features,5,index) # 训练集与测试集的切分\n",
    "    labels_test_data,labels_train_data=K_fold_split(labels,5,index)\n",
    "    features_train_norm,means,stds=normalize_data(features_train_data) # 训练集标准化\n",
    "    features_train_norm=tf.constant(features_train_norm)\n",
    "    labels_train_data=tf.constant(labels_train_data,dtype=tf.float32)\n",
    "    # 模型训练\n",
    "    model=Ann(input_size,hidden_size,output_size,tf.nn.relu)# 隐藏层使用relu进行激活\n",
    "    losses=train(model,max_epoch,lr,features_train_norm,labels_train_data)\n",
    "    # 测试集数据处理\n",
    "    features_test_data_norm=normalize_test_data(features_test_data,means,stds) # 测试集标准化\n",
    "    features_test_data_norm=tf.constant(features_test_data_norm)\n",
    "    y_pred=model(features_test_data_norm)\n",
    "    y_pred=classify(y_pred)\n",
    "    acc=accuracy(y_pred,labels_test_data)\n",
    "    accuracy_history.append(acc)\n",
    "average_accuracy=np.mean(accuracy_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Ann------------------\n",
      "index:0  accuracy:0.875\n",
      "index:1  accuracy:0.4375\n",
      "index:2  accuracy:0.75\n",
      "index:3  accuracy:0.8125\n",
      "index:4  accuracy:0.6875\n",
      "--------------average--------------\n",
      "average accuracy:0.7125\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------Ann------------------\")\n",
    "for index,acc in enumerate(accuracy_history):\n",
    "    print(\"index:{}  accuracy:{}\".format(index,acc))\n",
    "\n",
    "print(\"--------------average--------------\")\n",
    "print(\"average accuracy:{}\".format(np.mean(accuracy_history)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用SVM进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svmutil import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(data,type_num):\n",
    "    sample_num=data.shape[0]\n",
    "    onehot=np.zeros((sample_num,type_num))\n",
    "    for i,cls in enumerate(data):\n",
    "        onehot[i,int(cls[0])]=1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将dataframe转为libsvm的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_libsvm(df:pd.DataFrame,labels_col:int,output_file):\n",
    "    with open(output_file,'w') as f:\n",
    "        for _,row in df.iterrows():\n",
    "            label=row[labels_col]\n",
    "            features=row.drop(labels_col)\n",
    "            feature_str=' '.join([f\"{index}:{value}\" for index,value in features.items()])\n",
    "            line=f'{label} {feature_str}\\n'\n",
    "            f.write(line)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_k_fold(df,k,selected_index):\n",
    "    n=len(df)\n",
    "    chunk_size=n//k\n",
    "    remainder=n%k\n",
    "    if remainder == 0:\n",
    "        chunks=np.array_split(df,k)\n",
    "    else:\n",
    "        chunks=np.array_split(df.iloc[:-remainder],k)\n",
    "    \n",
    "    selected_chunk=chunks[selected_index]\n",
    "    remaining_chunks=np.concatenate(chunks[:selected_index]+chunks[selected_index+1:])\n",
    "    return pd.DataFrame(selected_chunk,columns=df.columns),pd.DataFrame(remaining_chunks,columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>81.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.5</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>73.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>65.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>74.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y     1     2\n",
       "0   1.0  55.5  69.5\n",
       "1   1.0  41.0  81.5\n",
       "2   1.0  53.5  86.0\n",
       "3   1.0  46.0  84.0\n",
       "4   1.0  41.0  73.5\n",
       "..  ...   ...   ...\n",
       "75 -1.0  20.0  65.5\n",
       "76 -1.0  38.0  65.0\n",
       "77 -1.0  18.5  74.5\n",
       "78 -1.0  16.0  72.5\n",
       "79 -1.0  33.5  68.0\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_raw=pd.concat([labels_raw,features_raw],axis=1)\n",
    "all_data_raw.columns=['y','1','2']\n",
    "all_data_raw['y']=all_data_raw['y'].replace(0,-1)\n",
    "all_data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接处理出5倍交叉分割所需的数据,生成过后注释掉了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=5\n",
    "# for index in range(k):\n",
    "#     df_test,df_train=dataframe_k_fold(all_data_raw,5,index)\n",
    "#     train_libsvm=dataframe_to_libsvm(df_train,'y',f'./data/data_train{index}.txt')\n",
    "#     test_libsvm=dataframe_to_libsvm(df_test,'y',f'./data/data_test{index}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    values_1=[item[1] for item in data]\n",
    "    values_2=[item[2] for item in data]\n",
    "    means=[np.mean(values_1),np.mean(values_2)]\n",
    "    stds=[np.std(values_1),np.std(values_2)]\n",
    "    for item in data:\n",
    "        item[1]=(item[1]-means[0])/stds[0]\n",
    "        item[2]=(item[2]-means[1])/stds[1]\n",
    "    return data,means,stds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test(data,means,stds):\n",
    "    for item in data:\n",
    "        item[1]=(item[1]-means[0])/stds[0]\n",
    "        item[2]=(item[2]-means[1])/stds[1]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来使用不同的核函数以及不同的c值分别进行5次交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 18.75% (3/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 31.25% (5/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 31.25% (5/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 31.25% (5/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 31.25% (5/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 0% (0/16) (classification)\n",
      "Accuracy = 25% (4/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 18.75% (3/16) (classification)\n",
      "Accuracy = 18.75% (3/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 81.25% (13/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 68.75% (11/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 62.5% (10/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 87.5% (14/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 56.25% (9/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n",
      "Accuracy = 37.5% (6/16) (classification)\n",
      "Accuracy = 50% (8/16) (classification)\n",
      "Accuracy = 93.75% (15/16) (classification)\n",
      "Accuracy = 43.75% (7/16) (classification)\n",
      "Accuracy = 75% (12/16) (classification)\n"
     ]
    }
   ],
   "source": [
    "k=5\n",
    "svm_types=['0']\n",
    "kernal_types=['0','1','2','3']\n",
    "cs=[round(x*0.1,1) for x in range(1,51)]\n",
    "svm_type_mp={\n",
    "    '0':'软间隔',\n",
    "}\n",
    "kernal_type_mp={\n",
    "    '0':'线性核函数',\n",
    "    '1':'多项式核函数',\n",
    "    '2':'径向基核函数',\n",
    "    '3':'Sigmoid核函数'\n",
    "}\n",
    "res=[]\n",
    "for svm_type in svm_types:\n",
    "    for kernal_type in kernal_types:\n",
    "        for c in cs:\n",
    "            accuracys=[]\n",
    "            for index in range(k):\n",
    "                train_y,train_x=svm_read_problem(f'./data/data_train{index}.txt')\n",
    "                test_y,test_x=svm_read_problem(f'./data/data_test{index}.txt')\n",
    "                train_x_norm,means,stds=normalize(train_x)\n",
    "                model=svm_train(train_y,train_x_norm,f'-s {svm_type} -t {kernal_type} -c {c}')\n",
    "                test_x=normalize_test(test_x,means,stds)\n",
    "                _,accuracy,_=svm_predict(test_y,test_x,model)\n",
    "                accuracys.append(accuracy[0])\n",
    "            average_accuracy=np.mean(accuracys)\n",
    "            res.append({\n",
    "                'svm_type':svm_type_mp[svm_type],\n",
    "                'kernal_type':kernal_type_mp[kernal_type],\n",
    "                \"c\":c,\n",
    "                'average_accuracy':average_accuracy\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.1, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.2, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.3, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.4, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.5, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.6, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.7, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.8, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 0.9, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.0, 'average_accuracy': 73.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.1, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.2, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.3, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.4, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.5, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.6, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.7, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.8, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.9, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.0, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.1, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.2, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.3, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.4, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.5, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.6, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.7, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.8, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 2.9, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.0, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.1, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.2, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.3, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.4, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.5, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.6, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.7, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.8, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 3.9, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.0, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.1, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.2, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.3, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.4, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.5, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.6, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.7, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.8, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 4.9, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 5.0, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.1, 'average_accuracy': 46.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.2, 'average_accuracy': 50.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.3, 'average_accuracy': 50.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.4, 'average_accuracy': 50.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.5, 'average_accuracy': 51.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.6, 'average_accuracy': 52.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.7, 'average_accuracy': 52.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.8, 'average_accuracy': 53.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 0.9, 'average_accuracy': 51.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.0, 'average_accuracy': 51.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.1, 'average_accuracy': 52.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.2, 'average_accuracy': 52.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.3, 'average_accuracy': 55.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.4, 'average_accuracy': 55.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.5, 'average_accuracy': 55.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.6, 'average_accuracy': 55.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.7, 'average_accuracy': 56.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.8, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 1.9, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.0, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.1, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.2, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.3, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.4, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.5, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.6, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.7, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.8, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 2.9, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.0, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.1, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.2, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.3, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.4, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.5, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.6, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.7, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.8, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 3.9, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.0, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.1, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.2, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.3, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.4, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.5, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.6, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.7, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.8, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 4.9, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '多项式核函数', 'c': 5.0, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.1, 'average_accuracy': 30.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.2, 'average_accuracy': 56.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.3, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.4, 'average_accuracy': 66.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.5, 'average_accuracy': 66.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.6, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.7, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.8, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 0.9, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.0, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.1, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.2, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.3, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.4, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.5, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.6, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.7, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.8, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 1.9, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.0, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.1, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.2, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.3, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.4, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.5, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.6, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.7, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.8, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 2.9, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.0, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.1, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.2, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.3, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.4, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.5, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.6, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.7, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.8, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 3.9, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.0, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.1, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.2, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.3, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.4, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.5, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.6, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.7, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.8, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 4.9, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': '径向基核函数', 'c': 5.0, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.1, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.2, 'average_accuracy': 66.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.3, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.4, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.5, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.6, 'average_accuracy': 73.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.7, 'average_accuracy': 73.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.8, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 0.9, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.0, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.1, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.2, 'average_accuracy': 72.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.3, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.4, 'average_accuracy': 70.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.5, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.6, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.7, 'average_accuracy': 71.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.8, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 1.9, 'average_accuracy': 68.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.0, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.1, 'average_accuracy': 66.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.2, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.3, 'average_accuracy': 67.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.4, 'average_accuracy': 65.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.5, 'average_accuracy': 63.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.6, 'average_accuracy': 63.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.7, 'average_accuracy': 63.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.8, 'average_accuracy': 63.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 2.9, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.0, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.1, 'average_accuracy': 60.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.2, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.3, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.4, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.5, 'average_accuracy': 60.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.6, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.7, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.8, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 3.9, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.0, 'average_accuracy': 57.5}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.1, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.2, 'average_accuracy': 61.25}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.3, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.4, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.5, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.6, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.7, 'average_accuracy': 58.75}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.8, 'average_accuracy': 60.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 4.9, 'average_accuracy': 60.0}\n",
      "{'svm_type': '软间隔', 'kernal_type': 'Sigmoid核函数', 'c': 5.0, 'average_accuracy': 60.0}\n",
      "表现最好的是:\n",
      "{'svm_type': '软间隔', 'kernal_type': '线性核函数', 'c': 1.0, 'average_accuracy': 73.75}\n"
     ]
    }
   ],
   "source": [
    "max_accuracy=0\n",
    "best_item=None\n",
    "for item in res:\n",
    "    if item['average_accuracy']>max_accuracy:\n",
    "        max_accuracy=item['average_accuracy']\n",
    "        best_item=item\n",
    "    print(item)\n",
    "print(\"表现最好的是:\")\n",
    "print(best_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过以上分析发现使用线性核函数，c为1.0时，进行5次交叉验证拥有最好的平均准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过使用基于随机梯度下降的logistic回归，三层前向神经网络，支持向量机发现，三者的预测效果在该数据集上相差不大，但是支持向量机的预测效果最稳定，经过多次实验发现其平均准确率始终稳定在一个值，而logistic和三层前向神经网络的准确率有时高有时低，但总体发现logistic回归的效果比三层前向神经网络要好。\n",
    "对于训练速度而言，支持向量机快于Logistc快于三层前向神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
