{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ann(torch.nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,activator,hidden_layer_size=0):\n",
    "        super().__init__()\n",
    "        self.input_layer=torch.nn.Linear(input_size,hidden_size)\n",
    "        self.output_layer=torch.nn.Linear(hidden_size,output_size)\n",
    "        self.activator=activator\n",
    "        self.hidden_layers=[]\n",
    "        for i in range(hidden_layer_size):\n",
    "            self.hidden_layers.append(torch.nn.Linear(hidden_size,hidden_size).to(torch.double))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x=self.fc1(x)\n",
    "        x=self.input_layer(x)\n",
    "        x=self.activator(x)\n",
    "        for i,layer in enumerate(self.hidden_layers):\n",
    "            x=layer(x)\n",
    "            x=self.activator(x)\n",
    "        x=self.output_layer(x)\n",
    "        x=torch.sigmoid(x)\n",
    "        return x    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_row=pd.read_csv('./ex4x.dat',header=None,sep=r'\\s+')\n",
    "labels_row=pd.read_csv('./ex4y.dat',header=None,sep=r'\\s+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 2),(80, 1)\n"
     ]
    }
   ],
   "source": [
    "features=np.column_stack((features_row[0].values.tolist(),features_row[1].values.tolist()))\n",
    "labels=np.array(labels_row[0].values.tolist()).reshape(-1,1)\n",
    "print('{},{}'.format(features.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K倍交叉验证切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_split(data,k,test_data_index):\n",
    "    data_copy=np.array(data)\n",
    "    splited_datas=np.array_split(data_copy,k)\n",
    "    test_data=splited_datas[test_data_index]\n",
    "    train_data=[]\n",
    "    for i in range(k):\n",
    "        if i==test_data_index:\n",
    "            continue\n",
    "        train_data.extend(splited_datas[i])\n",
    "    \n",
    "    train_data=np.array(train_data).reshape(-1,data.shape[1])\n",
    "    return test_data,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    res = np.array(data.T)\n",
    "    means = np.mean(res, axis=1)\n",
    "    stds = np.std(res, axis=1)\n",
    "    for i in range(res.shape[0]):\n",
    "        res[i] = (res[i] - means[i]) / stds[i]\n",
    "    res = res.T\n",
    "    return res, means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,max_epoch,lr,features_train_data,labels_train_data):\n",
    "    optimizer=torch.optim.SGD(model.parameters(),lr=lr)\n",
    "    losses=[]\n",
    "    for epoch in range(max_epoch):\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(features_train_data)\n",
    "        loss=nn.CrossEntropyLoss()(output.flatten(),labels_train_data.flatten())\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data,threshold=0.5):\n",
    "    res=torch.tensor(data)\n",
    "    for i in range(res.shape[0]):\n",
    "        if res[i][0]>=threshold:\n",
    "            res[i][0]=1\n",
    "        else:\n",
    "            res[i][0]=0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_test_data(test_data,means,stds):\n",
    "    res=np.array(test_data.T)\n",
    "    \n",
    "    for i in range(res.shape[0]):\n",
    "        res[i]=(res[i]-means[i])/stds[i]\n",
    "    \n",
    "    res=res.T\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction,labels_test_data):\n",
    "    equal_count=0\n",
    "    total=prediction.shape[0]\n",
    "    for i in range(prediction.shape[0]):\n",
    "        if prediction[i][0]==labels_test_data[i][0]:\n",
    "            equal_count+=1\n",
    "    \n",
    "    return equal_count/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "控制隐藏层层数为1，测试相同迭代次数下,不同神经元个数的模型表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes=[1,2,3,4,5,6,7,8,16,32,64,128]\n",
    "input_size=2\n",
    "output_size=1\n",
    "average_accuracy_history=[]\n",
    "for i,hidden_size in enumerate(hidden_sizes):\n",
    "    accuracy_history=[]\n",
    "    losses_history=[]\n",
    "    for index in range(5):\n",
    "        # print(\"-----------------------{}----------------------\".format(index))\n",
    "        # print(\"features:{}\".format(features))\n",
    "        features_test_data,features_train_data=K_fold_split(features,5,index) # 训练集与测试集的切分\n",
    "        # print(\"features_train_data:{}\".format(features_train_data))\n",
    "        labels_test_data,labels_train_data=K_fold_split(labels,5,index)\n",
    "        # print(\"labels_train_data:{}\".format(labels_train_data))\n",
    "        features_train_norm,means,stds=normalize_data(features_train_data) # 训练集标准化\n",
    "        features_train_norm=torch.from_numpy(features_train_norm)\n",
    "        labels_train_data=torch.from_numpy(labels_train_data)\n",
    "        # 开始训练\n",
    "        model=Ann(input_size,hidden_size,output_size,torch.nn.functional.sigmoid).to(torch.double)\n",
    "        max_epoch=2000\n",
    "        losses=train(model,max_epoch,0.1,features_train_norm,labels_train_data)\n",
    "        # losses_history.append(losses)\n",
    "        #开始测试\n",
    "        features_test_data_norm=normalize_test_data(features_test_data,means,stds) # 测试集标准化\n",
    "        features_test_data_norm=torch.from_numpy(features_test_data_norm)\n",
    "        y_pred=model.forward(features_test_data_norm)\n",
    "        y_pred=classify(y_pred)\n",
    "        acc=accuracy(y_pred,labels_test_data)\n",
    "        accuracy_history.append(acc)\n",
    "    \n",
    "    average_accuracy=np.mean(accuracy_history)\n",
    "    average_accuracy_history.append({\"{}\".format(hidden_size):\"{}\".format(average_accuracy)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': '0.7625'},\n",
       " {'2': '0.75'},\n",
       " {'3': '0.7375'},\n",
       " {'4': '0.7375'},\n",
       " {'5': '0.75'},\n",
       " {'6': '0.75'},\n",
       " {'7': '0.75'},\n",
       " {'8': '0.75'},\n",
       " {'16': '0.75'},\n",
       " {'32': '0.7625'},\n",
       " {'64': '0.75'},\n",
       " {'128': '0.75'}]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上是对应不同神经元个数的平均预测准确率，发现并不是神经元越多就有更好的预测效果，1和2的数量反而更适合这组数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取神经元个数为2，试用不同的中间层激活函数进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=2\n",
    "input_size=2\n",
    "output_size=1\n",
    "max_epoch=2000\n",
    "average_accuracy_history=[]\n",
    "import torch.nn.functional as fn\n",
    "activators=[fn.sigmoid,fn.tanh,fn.relu,fn.leaky_relu,fn.elu]\n",
    "for i,activator in enumerate(activators):\n",
    "    accuracy_history=[]\n",
    "    losses_history=[]\n",
    "    for index in range(5):\n",
    "        # 数据准备\n",
    "        features_test_data,features_train_data=K_fold_split(features,5,index) # 训练集与测试集的切分\n",
    "        labels_test_data,labels_train_data=K_fold_split(labels,5,index)\n",
    "        features_train_norm,means,stds=normalize_data(features_train_data) # 训练集标准化\n",
    "        features_train_norm=torch.from_numpy(features_train_norm)\n",
    "        labels_train_data=torch.from_numpy(labels_train_data)\n",
    "        # 开始训练\n",
    "        model=Ann(input_size,hidden_size,output_size,activator,1).to(torch.double)\n",
    "        losses=train(model,max_epoch,0.1,features_train_norm,labels_train_data)\n",
    "        #开始测试\n",
    "        features_test_data_norm=normalize_test_data(features_test_data,means,stds) # 测试集标准化\n",
    "        features_test_data_norm=torch.from_numpy(features_test_data_norm)\n",
    "        y_pred=model.forward(features_test_data_norm)\n",
    "        y_pred=classify(y_pred)\n",
    "        acc=accuracy(y_pred,labels_test_data)\n",
    "        accuracy_history.append(acc)\n",
    "        \n",
    "    average_accuracy=np.mean(accuracy_history)\n",
    "    average_accuracy_history.append({\"{}\".format(activator.__name__):\"{}\".format(average_accuracy)})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sigmoid': '0.775'},\n",
       " {'tanh': '0.7375'},\n",
       " {'relu': '0.7125'},\n",
       " {'leaky_relu': '0.7375'},\n",
       " {'elu': '0.7375'}]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过实验可以发现使用relu或leaky_relu作为隐藏层激活函数有更好的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size=2\n",
    "input_size=2\n",
    "output_size=1\n",
    "max_epoch=2000\n",
    "hidden_layer_size=[1,2,3,4,8,16]\n",
    "average_accuracy_history=[]\n",
    "\n",
    "import torch.nn.functional as fn\n",
    "activator=fn.relu\n",
    "\n",
    "for i,layer_size in enumerate(hidden_layer_size):\n",
    "    accuracy_history=[]\n",
    "    losses_history=[]\n",
    "    for index in range(5):\n",
    "        # 数据准备\n",
    "        features_test_data,features_train_data=K_fold_split(features,5,index) # 训练集与测试集的切分\n",
    "        labels_test_data,labels_train_data=K_fold_split(labels,5,index)\n",
    "        features_train_norm,means,stds=normalize_data(features_train_data) # 训练集标准化\n",
    "        features_train_norm=torch.from_numpy(features_train_norm)\n",
    "        labels_train_data=torch.from_numpy(labels_train_data)\n",
    "        # 开始训练\n",
    "        model=Ann(input_size,hidden_size,output_size,activator,layer_size).to(torch.double)\n",
    "        losses=train(model,max_epoch,0.1,features_train_norm,labels_train_data)\n",
    "        #开始测试\n",
    "        features_test_data_norm=normalize_test_data(features_test_data,means,stds) # 测试集标准化\n",
    "        features_test_data_norm=torch.from_numpy(features_test_data_norm)\n",
    "        y_pred=model.forward(features_test_data_norm)\n",
    "        y_pred=classify(y_pred)\n",
    "        acc=accuracy(y_pred,labels_test_data)\n",
    "        accuracy_history.append(acc)\n",
    "        \n",
    "    average_accuracy=np.mean(accuracy_history)\n",
    "    average_accuracy_history.append({\"{}\".format(layer_size):\"{}\".format(average_accuracy)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'1': '0.5875'},\n",
       " {'2': '0.7375'},\n",
       " {'3': '0.6125'},\n",
       " {'4': '0.35'},\n",
       " {'8': '0.5'},\n",
       " {'16': '0.9'}]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多次试验后发现隐藏层为3时平均效果最好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么接下来使用2神经元，3层隐藏层，relu激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as fn\n",
    "activator=fn.relu\n",
    "hidden_size=2\n",
    "layer_size=3\n",
    "\n",
    "for index in range(5):\n",
    "    # 数据准备\n",
    "    features_test_data,features_train_data=K_fold_split(features,5,index) # 训练集与测试集的切分\n",
    "    labels_test_data,labels_train_data=K_fold_split(labels,5,index)\n",
    "    features_train_norm,means,stds=normalize_data(features_train_data) # 训练集标准化\n",
    "    features_train_norm=torch.from_numpy(features_train_norm)\n",
    "    labels_train_data=torch.from_numpy(labels_train_data)\n",
    "    # 开始训练\n",
    "    model=Ann(input_size,hidden_size,output_size,activator,layer_size).to(torch.double)\n",
    "    losses=train(model,max_epoch,0.1,features_train_norm,labels_train_data)\n",
    "    #开始测试\n",
    "    features_test_data_norm=normalize_test_data(features_test_data,means,stds) # 测试集标准化\n",
    "    features_test_data_norm=torch.from_numpy(features_test_data_norm)\n",
    "    y_pred=model.forward(features_test_data_norm)\n",
    "    y_pred=classify(y_pred)\n",
    "    acc=accuracy(y_pred,labels_test_data)\n",
    "    accuracy_history.append(acc)\n",
    "    \n",
    "average_accuracy=np.mean(accuracy_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91875"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现平均准确率高达0.91875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
